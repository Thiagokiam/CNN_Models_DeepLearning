{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Bvfvt8jfaRis074dgj7sU10wxT7_HFf-",
      "authorship_tag": "ABX9TyOAAIO/gplwqMfcXWnQFZoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thiagokiam/CNN_Models_DeepLearning/blob/main/Save_DataSet_TensorData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rla_ddGNCAxt"
      },
      "outputs": [],
      "source": [
        "# Tratamento dos dados\n",
        "import cv2 as cv\n",
        "import time, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Implementação e treinamento da rede\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "# Carregamento de Dados\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# Plots e análises\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ConversaoDataFrame (diretorio_imagens, diretorio_dados, diretorio_perneabilidade):\n",
        "  # Diretórios das imagens e dos dados\n",
        "  diretorio_imagens = diretorio_imagens\n",
        "  diretorio_dados = diretorio_dados\n",
        "  diretorio_perneabilidade = diretorio_perneabilidade\n",
        "\n",
        "  arquivos = sorted(os.listdir(diretorio_imagens))\n",
        "  dados = sorted(os.listdir(diretorio_dados))\n",
        "\n",
        "  dados_permeabilidade = pd.read_excel(diretorio_perneabilidade, sheet_name = 'Planilha1')\n",
        "  dados_permeabilidade['Permeabilidade (mD)'][0]\n",
        "\n",
        "  # Coletando cada uma das imagens\n",
        "  imagem = []\n",
        "  for i in np.arange(len(arquivos)):\n",
        "    diretorio = diretorio_imagens + str(arquivos[i]) + '/'\n",
        "    lista_imagens = sorted(os.listdir(diretorio))\n",
        "    img = []\n",
        "    for j in np.arange(len(lista_imagens)):\n",
        "      diretorio_imgem = diretorio + lista_imagens[j]\n",
        "      img.append(cv.imread(diretorio_imgem, cv.IMREAD_GRAYSCALE))\n",
        "    imagem.append(img)\n",
        "\n",
        "  amostras = len(imagem)        # Quantidade de amostras\n",
        "  n_imagens = len(imagem[0])    # Quantidade de imagens que cada amostra possui\n",
        "\n",
        "  # Coletando cada um dos Threshould's\n",
        "  dados_threshould = []\n",
        "  nome_amostra = []\n",
        "  for i in np.arange(amostras):\n",
        "    dir_dados = diretorio_dados + str(dados[i])\n",
        "    arqu = pd.read_csv(dir_dados, sep = ':').T.reset_index().drop('index', axis = 1).T\n",
        "    treshould = []\n",
        "    for j in np.arange(n_imagens):\n",
        "      treshould.append(int(arqu[1][j][1:-4]))\n",
        "      nome_amostra.append(dados[i][:3])\n",
        "    dados_threshould.append(treshould)\n",
        "\n",
        "\n",
        "  # Obtendo os histogramas, a escala de cinza e a multiplicação\n",
        "  escala_cinza = np.arange(255, -1, -1)\n",
        "  histogramas = []\n",
        "  multiplicacao_hist_cinza = []\n",
        "  soma_multiplicacao = []\n",
        "\n",
        "  for i in np.arange(amostras):\n",
        "    threshould = dados_threshould[i]\n",
        "    image = imagem[i]\n",
        "    histograma = []\n",
        "    multiplicacao = []\n",
        "    soma = []\n",
        "    for j in np.arange(n_imagens):\n",
        "      histg = cv.calcHist([image[j]], [0], None, [256], [0,256])\n",
        "      mult = histg[:threshould[j]].T[0]*escala_cinza[:threshould[j]]\n",
        "      histograma.append(histg)\n",
        "      multiplicacao.append(mult)\n",
        "      soma.append(sum(mult))\n",
        "    histogramas.append(histograma)\n",
        "    multiplicacao_hist_cinza.append(multiplicacao)\n",
        "    soma_multiplicacao.append(soma)\n",
        "\n",
        "\n",
        "  # Calculando a permeabilidade em cada Slice\n",
        "  permeabilidade_slice = []\n",
        "  for i in np.arange(amostras):\n",
        "    k_slice = []\n",
        "    for j in np.arange(n_imagens):\n",
        "      soma_amostra = sum(soma_multiplicacao[i])/n_imagens\n",
        "      k_gas = dados_permeabilidade['Permeabilidade (mD)'][i]\n",
        "      soma_slice = soma_multiplicacao[i][j]\n",
        "      k_slice.append(k_gas*soma_slice/soma_amostra)\n",
        "    permeabilidade_slice.append(k_slice)\n",
        "\n",
        "  # Criando DataFrame com os dados da imagem e permeabilidade\n",
        "  lista_imagem = []\n",
        "  permeabilidade_input = []\n",
        "  for i in np.arange(amostras):\n",
        "    for j in np.arange(n_imagens):\n",
        "      #reshape = imagem[i][j].reshape(1, pixel_imagem*pixel_imagem)\n",
        "      lista_imagem.append(imagem[i][j])\n",
        "      permeabilidade_input.append(permeabilidade_slice[i][j])\n",
        "\n",
        "  dados_entrada = pd.DataFrame({'Amostra': nome_amostra,\n",
        "                                'Imagem': lista_imagem,\n",
        "                                'Permeabilidade': permeabilidade_input})\n",
        "\n",
        "  return dados_entrada"
      ],
      "metadata": {
        "id": "LNsZBhrsCKiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diretorio_perneabilidade = '/content/drive/MyDrive/Projeto_CNN/Dados_petrofisicos_tentativa_-nova.xlsx', sheetname = 'Teste'"
      ],
      "metadata": {
        "id": "LTLoyZT22aBQ",
        "outputId": "7bc8288c-0c98-46d4-a645-989580e4f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (<ipython-input-1-eeea75551f2d>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-eeea75551f2d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    diretorio_perneabilidade = '/content/drive/MyDrive/Projeto_CNN/Dados_petrofisicos_tentativa_-nova.xlsx', sheetname = 'Teste'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diretorio_imagens = '/content/drive/MyDrive/Projeto_CNN/Imagens/'\n",
        "diretorio_dados = '/content/drive/MyDrive/Projeto_CNN/Dados_Threshould/'\n",
        "diretorio_perneabilidade = '/content/drive/MyDrive/Projeto_CNN/Dados_petrofisicos_tentativa_-nova.xlsx', sheetname = 'Teste'\n",
        "df = ConversaoDataFrame(diretorio_imagens,diretorio_dados, diretorio_perneabilidade)\n"
      ],
      "metadata": {
        "id": "HgaCM8VLCLB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('/content/drive/MyDrive/ModelCNN/Dados_petrofisicos.xlsx')"
      ],
      "metadata": {
        "id": "nIGRTQcfkomx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[\"Imagem\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qby58i_ynEVw",
        "outputId": "aa69ed83-2343-432d-cf5e-264eb6a032b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "450"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criando tensores\n",
        "imagem_tensor = []\n",
        "perm=np.log10(df['Permeabilidade']*1000)\n",
        "permeabilidade_tns = torch.from_numpy(np.array(perm).astype(np.float16))\n",
        "for i in np.arange(len(df)):\n",
        "  con_tns = torch.Tensor(df['Imagem'][i])\n",
        "  img_tns = con_tns.view(1, con_tns.size(0), con_tns.size(1))\n",
        "  imagem_tensor.append(img_tns)\n",
        "\n",
        "print(len(img_tns))\n",
        "print(permeabilidade_tns[1])\n",
        "print(df['Permeabilidade'][5])"
      ],
      "metadata": {
        "id": "R-ZSv2jzCn_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aleatorizando os atributos e rótulos\n",
        "X_image, y_perm = imagem_tensor, permeabilidade_tns\n",
        "torch.save(X_image, '/content/drive/MyDrive/Projeto_CNN/Tensores/atributos_random_tensor_n_aleatorio.pt')\n",
        "torch.save(y_perm, '/content/drive/MyDrive/Projeto_CNN/Tensores/rotulos_random_tensor_n_aleatorio.pt')"
      ],
      "metadata": {
        "id": "3Muy2nJMTLWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "estQD7SICK3t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}